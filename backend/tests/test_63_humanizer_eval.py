#!/usr/bin/env python3
"""
[éœ€æ±‚ç‚¹ 63] Humanizer Agent å» AI å‘³ â€” LLM-as-Judge ç‰¹æ€§éªŒæ”¶

å¯¹é½æ–¹æ¡ˆæ–‡æ¡£ï¼švibe-blog-plan-æ–¹æ¡ˆ/63.02.éœ€æ±‚æ–‡æ¡£.md

éªŒè¯é€»è¾‘ï¼š
  1. å‡†å¤‡ä¸€æ®µå…¸å‹çš„ AI å‘³æ–‡æœ¬ï¼ˆå«å·²çŸ¥ AI å†™ä½œç—•è¿¹ï¼‰
  2. è°ƒç”¨ HumanizerAgent å¤„ç†
  3. æŠŠã€ŒåŸæ–‡ + æ”¹å†™åæ–‡æœ¬ã€äº¤ç»™ LLM Judge è¯„ä¼°
  4. LLM é€é¡¹æ£€æŸ¥æ”¹å†™æ˜¯å¦æ¶ˆé™¤äº† AI ç—•è¿¹ï¼ŒåŒæ—¶ä¿ç•™äº†å†…å®¹å®Œæ•´æ€§

æ£€æŸ¥é¡¹ï¼ˆå¯¹é½ 63.02 éœ€æ±‚æ–‡æ¡£ï¼‰ï¼š
  C1 AI è¯æ±‡æ¶ˆé™¤   â€” æ”¹å†™åæ˜¯å¦æ¶ˆé™¤äº† AI é«˜é¢‘è¯æ±‡ï¼ˆæ­¤å¤–ã€è‡³å…³é‡è¦ã€æ ¼å±€ç­‰ï¼‰
  C2 å¡«å……çŸ­è¯­æ¶ˆé™¤   â€” æ”¹å†™åæ˜¯å¦æ¶ˆé™¤äº†å¡«å……çŸ­è¯­ï¼ˆå€¼å¾—æ³¨æ„çš„æ˜¯ã€ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ç­‰ï¼‰
  C3 ç»“æ„å»å…¬å¼åŒ–   â€” æ”¹å†™åæ˜¯å¦æ‰“ç ´äº†ä¸‰æ®µå¼ã€å¦å®šå¼æ’æ¯”ç­‰å…¬å¼ç»“æ„
  C4 å†…å®¹å®Œæ•´æ€§     â€” æ”¹å†™åæ˜¯å¦ä¿ç•™äº†æ ¸å¿ƒäº‹å®ã€æ•°æ®å’ŒæŠ€æœ¯ç»†èŠ‚
  C5 å ä½ç¬¦ä¿ç•™     â€” æ”¹å†™åæ˜¯å¦ä¿ç•™äº† {source_NNN}ã€[IMAGE: xxx] ç­‰å ä½ç¬¦
  C6 è‡ªç„¶åº¦æå‡     â€” æ”¹å†™åè¯»èµ·æ¥æ˜¯å¦æ›´åƒäººç±»å†™çš„

é€šè¿‡æ ‡å‡†ï¼š6 é¡¹ä¸­è‡³å°‘ 5 é¡¹ pass

ç”¨æ³•ï¼š
  cd backend
  python tests/test_63_humanizer_eval.py
  python tests/test_63_humanizer_eval.py --skip-generate  # è·³è¿‡ç”Ÿæˆï¼Œç›´æ¥ç”¨æ ·æœ¬æµ‹è¯•
"""

import os
import sys
import json
import time
import argparse
import logging
from pathlib import Path
from datetime import datetime

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger(__name__)

# ============================================================
# é…ç½®
# ============================================================

BACKEND_URL = os.environ.get("BACKEND_URL", "http://localhost:5001")
RESULTS_DIR = Path(__file__).parent / "eval_results" / "63"
PASS_THRESHOLD = 5  # 6 é¡¹ä¸­è‡³å°‘ 5 é¡¹ pass

# ============================================================
# æµ‹è¯•æ ·æœ¬ï¼šå…¸å‹ AI å‘³æ–‡æœ¬ï¼ˆå«å·²çŸ¥ AI å†™ä½œç—•è¿¹ï¼‰
# ============================================================

AI_FLAVORED_SAMPLES = [
    {
        "title": "LangGraph æ¡†æ¶æ·±åº¦è§£æ",
        "content": """### LangGraph æ¡†æ¶æ·±åº¦è§£æ

æ­¤å¤–ï¼ŒLangGraph ä½œä¸ºä¸€ä¸ªè‡³å…³é‡è¦çš„å¤š Agent ç¼–æ’æ¡†æ¶ï¼Œåœ¨ä¸æ–­æ¼”å˜çš„ AI æ ¼å±€ä¸­å‘æŒ¥ç€å…³é”®æ€§çš„ä½œç”¨ã€‚å®ƒä¸ä»…ä»…æ˜¯ä¸€ä¸ªç®€å•çš„å·¥å…·ï¼Œè€Œæ˜¯ä¸€ç§å…¨æ–°çš„èŒƒå¼ï¼Œæ ‡å¿—ç€ AI åº”ç”¨å¼€å‘çš„é‡è¦è½¬æŠ˜ç‚¹ã€‚{source_001}

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒLangGraph çš„æ ¸å¿ƒè®¾è®¡ç†å¿µä½“ç°äº†å¯¹çŠ¶æ€ç®¡ç†ã€æµç¨‹æ§åˆ¶å’Œå¯è§‚æµ‹æ€§çš„æ·±åˆ»ç†è§£ã€‚è¿™ä¸€æ¡†æ¶ä¸ºå¼€å‘è€…æä¾›äº†æ— ç¼ã€ç›´è§‚å’Œå¼ºå¤§çš„å¼€å‘ä½“éªŒâ€”â€”ç¡®ä¿ç”¨æˆ·èƒ½å¤Ÿé«˜æ•ˆåœ°æ„å»ºå¤æ‚çš„ AI å·¥ä½œæµã€‚

[IMAGE: langgraph_architecture]

ä»ç®€å•çš„çº¿æ€§æµç¨‹åˆ°å¤æ‚çš„å¤š Agent åä½œï¼ŒLangGraph å±•ç¤ºäº†å…¶åœ¨ä¸åŒåœºæ™¯ä¸‹çš„å……æ»¡æ´»åŠ›çš„é€‚åº”èƒ½åŠ›ã€‚è¡Œä¸šä¸“å®¶è®¤ä¸ºï¼Œè¿™ä¸€æ¡†æ¶å°†å¯¹æ•´ä¸ª AI å¼€å‘ç”Ÿæ€äº§ç”ŸæŒä¹…å½±å“ï¼Œå½°æ˜¾äº† LangChain å›¢é˜Ÿåœ¨æŠ€æœ¯åˆ›æ–°æ–¹é¢çš„å…³é”®ä½œç”¨ã€‚{source_002}

**å…³é”®ç‰¹æ€§ï¼š** LangGraph æ‹¥æœ‰ä»¥ä¸‹æ ¸å¿ƒèƒ½åŠ›ï¼š
- **çŠ¶æ€ç®¡ç†ï¼š** æä¾›äº†ä¸°å¯Œçš„çŠ¶æ€ç®¡ç†æœºåˆ¶ï¼Œç¡®ä¿æ•°æ®åœ¨èŠ‚ç‚¹é—´çš„æ— ç¼æµè½¬
- **æ£€æŸ¥ç‚¹ï¼š** æ”¯æŒå¼€åˆ›æ€§çš„æ£€æŸ¥ç‚¹åŠŸèƒ½ï¼Œä¸ºé•¿æ—¶é—´è¿è¡Œçš„å·¥ä½œæµæä¾›å¯é ä¿éšœ
- **äººæœºåä½œï¼š** å®ç°äº†ä»¤äººå¹ä¸ºè§‚æ­¢çš„äººæœºåä½œæ¨¡å¼ï¼Œå¢å¼ºäº†ç³»ç»Ÿçš„çµæ´»æ€§

[CODE: langgraph_example]

å°½ç®¡ LangGraph é¢ä¸´ç€ä¸€äº›æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å­¦ä¹ æ›²çº¿å’Œæ€§èƒ½ä¼˜åŒ–ï¼Œä½†å‡­å€Ÿå…¶æˆ˜ç•¥ä½ç½®å’Œæ­£åœ¨è¿›è¡Œçš„æ”¹è¿›ï¼ŒLangGraph ç»§ç»­è“¬å‹ƒå‘å±•ã€‚æœªæ¥å±•æœ›ä»¤äººæœŸå¾…ï¼Œæ¿€åŠ¨äººå¿ƒçš„æ—¶ä»£å³å°†åˆ°æ¥ã€‚ğŸš€""",
        "audience_adaptation": "technical-beginner",
    },
]

# ============================================================
# LLM-as-Judge Prompt
# ============================================================

JUDGE_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„ AI å†™ä½œç—•è¿¹æ£€æµ‹ä¸“å®¶ã€‚

ä½ å°†çœ‹åˆ°ä¸€æ®µæ–‡æœ¬çš„ã€ŒåŸæ–‡ã€å’Œç»è¿‡ Humanizer Agent å¤„ç†åçš„ã€Œæ”¹å†™ç‰ˆã€ã€‚
ä½ éœ€è¦æ£€æŸ¥æ”¹å†™æ˜¯å¦æœ‰æ•ˆæ¶ˆé™¤äº† AI å†™ä½œç—•è¿¹ï¼ŒåŒæ—¶ä¿ç•™äº†å†…å®¹å®Œæ•´æ€§ã€‚

## åŸæ–‡
{original}

## æ”¹å†™å
{humanized}

---

è¯·é€é¡¹æ£€æŸ¥ä»¥ä¸‹ 6 ä¸ªç»´åº¦ï¼š

### C1 AI è¯æ±‡æ¶ˆé™¤
æ£€æŸ¥ï¼šæ”¹å†™åæ˜¯å¦æ¶ˆé™¤äº† AI é«˜é¢‘è¯æ±‡ï¼Ÿ
å¸¸è§ AI è¯æ±‡ï¼šæ­¤å¤–ã€è‡³å…³é‡è¦ã€æ ¼å±€ã€å…³é”®æ€§çš„ã€å……æ»¡æ´»åŠ›çš„ã€ä¸æ–­æ¼”å˜çš„ã€æ·±åˆ»çš„ã€æ— ç¼ã€å¼€åˆ›æ€§çš„ã€ä»¤äººå¹ä¸ºè§‚æ­¢çš„
- pass: ä¸Šè¿°è¯æ±‡åœ¨æ”¹å†™ååŸºæœ¬æ¶ˆé™¤ï¼ˆæ®‹ç•™ â‰¤ 1 ä¸ªï¼‰
- fail: ä»æœ‰ 2 ä¸ªä»¥ä¸Š AI é«˜é¢‘è¯æ±‡

### C2 å¡«å……çŸ­è¯­æ¶ˆé™¤
æ£€æŸ¥ï¼šæ”¹å†™åæ˜¯å¦æ¶ˆé™¤äº†å¡«å……çŸ­è¯­ï¼Ÿ
å¸¸è§å¡«å……çŸ­è¯­ï¼šå€¼å¾—æ³¨æ„çš„æ˜¯ã€ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ã€åœ¨è¿™ä¸ªæ—¶é—´ç‚¹ã€ç”±äº...çš„äº‹å®
- pass: å¡«å……çŸ­è¯­åœ¨æ”¹å†™ååŸºæœ¬æ¶ˆé™¤
- fail: ä»æœ‰æ˜æ˜¾çš„å¡«å……çŸ­è¯­

### C3 ç»“æ„å»å…¬å¼åŒ–
æ£€æŸ¥ï¼šæ”¹å†™åæ˜¯å¦æ‰“ç ´äº† AI å…¬å¼åŒ–ç»“æ„ï¼Ÿ
å¸¸è§å…¬å¼ï¼šä¸‰æ®µå¼åˆ—ä¸¾ã€å¦å®šå¼æ’æ¯”ï¼ˆä¸ä»…ä»…æ˜¯...è€Œæ˜¯...ï¼‰ã€é€šç”¨ç§¯æç»“è®ºï¼ˆæœªæ¥å±•æœ›ä»¤äººæœŸå¾…ï¼‰
- pass: å…¬å¼åŒ–ç»“æ„è¢«æ‰“ç ´æˆ–é‡å†™
- fail: ä»ä¿ç•™æ˜æ˜¾çš„å…¬å¼åŒ–ç»“æ„

### C4 å†…å®¹å®Œæ•´æ€§
æ£€æŸ¥ï¼šæ”¹å†™åæ˜¯å¦ä¿ç•™äº†æ ¸å¿ƒäº‹å®ã€æ•°æ®å’ŒæŠ€æœ¯ç»†èŠ‚ï¼Ÿ
- pass: æ ¸å¿ƒæŠ€æœ¯ä¿¡æ¯ï¼ˆLangGraph çš„åŠŸèƒ½ã€ç‰¹æ€§ï¼‰å®Œæ•´ä¿ç•™ï¼Œæ²¡æœ‰äº‹å®æ€§é”™è¯¯
- fail: ä¸¢å¤±äº†é‡è¦çš„æŠ€æœ¯ä¿¡æ¯æˆ–å¼•å…¥äº†äº‹å®æ€§é”™è¯¯

### C5 å ä½ç¬¦ä¿ç•™
æ£€æŸ¥ï¼šæ”¹å†™åæ˜¯å¦ä¿ç•™äº†æ‰€æœ‰å ä½ç¬¦ï¼Ÿ
éœ€è¦ä¿ç•™çš„å ä½ç¬¦ï¼š{{source_001}}ã€{{source_002}}ã€[IMAGE: langgraph_architecture]ã€[CODE: langgraph_example]
- pass: æ‰€æœ‰å ä½ç¬¦å®Œæ•´ä¿ç•™
- fail: æœ‰å ä½ç¬¦ä¸¢å¤±æˆ–è¢«ä¿®æ”¹

### C6 è‡ªç„¶åº¦æå‡
æ£€æŸ¥ï¼šæ”¹å†™åè¯»èµ·æ¥æ˜¯å¦æ›´åƒäººç±»å†™çš„ï¼Ÿ
- pass: å¥å¼æ›´è‡ªç„¶ã€èŠ‚å¥æœ‰å˜åŒ–ã€ä¸åƒæœºå™¨ç”Ÿæˆ
- fail: ä»ç„¶è¯»èµ·æ¥åƒ AI ç”Ÿæˆçš„æ–‡æœ¬

---

è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼ˆä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ï¼‰ã€‚æ¯ä¸ª reason é™ 20 å­—ä»¥å†…ï¼š

```json
{{
  "checks": {{
    "C1_ai_vocabulary": {{"result": "pass", "reason": "..."}},
    "C2_filler_phrases": {{"result": "pass", "reason": "..."}},
    "C3_structure": {{"result": "pass", "reason": "..."}},
    "C4_content_integrity": {{"result": "pass", "reason": "..."}},
    "C5_placeholders": {{"result": "pass", "reason": "..."}},
    "C6_naturalness": {{"result": "pass", "reason": "..."}}
  }},
  "pass_count": 0,
  "total": 6,
  "verdict": "PASS æˆ– FAIL",
  "summary": "ä¸€å¥è¯æ€»ç»“"
}}
```
"""

# ============================================================
# æ£€æŸ¥é¡¹å®šä¹‰
# ============================================================

CHECK_NAMES = {
    "C1_ai_vocabulary": "C1 AI è¯æ±‡æ¶ˆé™¤",
    "C2_filler_phrases": "C2 å¡«å……çŸ­è¯­æ¶ˆé™¤",
    "C3_structure": "C3 ç»“æ„å»å…¬å¼åŒ–",
    "C4_content_integrity": "C4 å†…å®¹å®Œæ•´æ€§",
    "C5_placeholders": "C5 å ä½ç¬¦ä¿ç•™",
    "C6_naturalness": "C6 è‡ªç„¶åº¦æå‡",
}
CHECK_KEYS = list(CHECK_NAMES.keys())


# ============================================================
# å·¥å…·å‡½æ•°
# ============================================================

def get_llm_client():
    """è·å– LLM å®¢æˆ·ç«¯"""
    sys.path.insert(0, str(Path(__file__).parent.parent))
    from services.llm_service import get_llm_service, init_llm_service

    llm = get_llm_service()
    if llm is None:
        # æœªé€šè¿‡ Flask app åˆå§‹åŒ–ï¼Œæ‰‹åŠ¨ä» config åˆå§‹åŒ–
        from config import get_config
        cfg = get_config()
        llm = init_llm_service({
            'AI_PROVIDER_FORMAT': cfg.AI_PROVIDER_FORMAT,
            'OPENAI_API_KEY': cfg.OPENAI_API_KEY,
            'OPENAI_API_BASE': cfg.OPENAI_API_BASE,
            'GOOGLE_API_KEY': getattr(cfg, 'GOOGLE_API_KEY', ''),
            'TEXT_MODEL': cfg.TEXT_MODEL,
        })
    return llm


def run_humanizer(sample: dict, llm_client) -> dict:
    """è°ƒç”¨ HumanizerAgent å¤„ç†æ ·æœ¬"""
    from services.blog_generator.agents.humanizer import HumanizerAgent

    agent = HumanizerAgent(llm_client)
    state = {
        'sections': [{
            'id': 'test_section',
            'title': sample['title'],
            'content': sample['content'],
        }],
        'audience_adaptation': sample.get('audience_adaptation', 'technical-beginner'),
    }

    logger.info(f"  [Humanizer] å¤„ç†ç« èŠ‚: {sample['title']}")
    start = time.time()
    result_state = agent.run(state)
    elapsed = time.time() - start

    section = result_state['sections'][0]
    humanized_content = section.get('content', '')
    skipped = section.get('humanizer_skipped', False)
    score_before = section.get('humanizer_score_before', section.get('humanizer_score', 0))
    score_after = section.get('humanizer_score_after', score_before)

    logger.info(
        f"  [Humanizer] å®Œæˆ ({elapsed:.1f}s): "
        f"è¯„åˆ† {score_before} â†’ {score_after}, "
        f"{'è·³è¿‡' if skipped else 'å·²æ”¹å†™'}"
    )

    return {
        'original': sample['content'],
        'humanized': humanized_content,
        'skipped': skipped,
        'score_before': score_before,
        'score_after': score_after,
        'elapsed': elapsed,
    }


def call_judge(original: str, humanized: str, llm_client) -> dict:
    """è°ƒç”¨ LLM Judge è¯„ä¼°æ”¹å†™æ•ˆæœ"""
    prompt = JUDGE_PROMPT.format(
        original=original,
        humanized=humanized,
    )

    logger.info("  [Judge] LLM è¯„ä¼°ä¸­...")
    response = llm_client.chat(
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"},
    )

    text = response.strip()
    if '```json' in text:
        start = text.find('```json') + 7
        end = text.find('```', start)
        text = text[start:end].strip()
    elif '```' in text:
        start = text.find('```') + 3
        end = text.find('```', start)
        text = text[start:end].strip()

    return json.loads(text, strict=False)


def print_eval_report(sample: dict, humanizer_result: dict, eval_result: dict):
    """æ‰“å°éªŒæ”¶æŠ¥å‘Š"""
    checks = eval_result.get("checks", {})
    pass_count = sum(1 for k in CHECK_KEYS if checks.get(k, {}).get("result") == "pass")
    verdict = "PASS" if pass_count >= PASS_THRESHOLD else "FAIL"

    # è¦†ç›– LLM è¿”å›çš„ pass_count å’Œ verdictï¼ˆä»¥å®é™…è®¡ç®—ä¸ºå‡†ï¼‰
    eval_result["pass_count"] = pass_count
    eval_result["verdict"] = verdict

    print("\n" + "=" * 70)
    print(f"ğŸ“Š Humanizer éªŒæ”¶æŠ¥å‘Š: {sample['title']}")
    print(f"   æ–¹æ¡ˆ: 63 â€” Humanizer Agent å» AI å‘³")
    print(f"   è¯„åˆ†: {humanizer_result['score_before']} â†’ {humanizer_result['score_after']}/50")
    print(f"   è€—æ—¶: {humanizer_result['elapsed']:.1f}s")
    print(f"   é€šè¿‡æ ‡å‡†: {PASS_THRESHOLD}/{len(CHECK_KEYS)} é¡¹ pass")
    print("=" * 70)

    for key in CHECK_KEYS:
        check = checks.get(key, {})
        result = check.get("result", "unknown")
        icon = "âœ…" if result == "pass" else "âŒ"
        print(f"\n  {icon} {CHECK_NAMES[key]}: {result.upper()}")
        print(f"     è¯æ®: {check.get('evidence', 'N/A')}")
        print(f"     ç†ç”±: {check.get('reason', 'N/A')}")

    print(f"\n{'=' * 70}")
    verdict_icon = "ğŸ‰" if verdict == "PASS" else "ğŸ’¥"
    print(f"  {verdict_icon} æ€»ä½“åˆ¤å®š: {verdict} ({pass_count}/{len(CHECK_KEYS)} é¡¹é€šè¿‡)")
    print(f"  ğŸ“ æ€»ç»“: {eval_result.get('summary', 'N/A')}")
    print("=" * 70)


def run_eval(sample: dict, llm_client) -> dict | None:
    """è¿è¡Œå®Œæ•´çš„éªŒæ”¶æµç¨‹"""
    print(f"\nğŸ“ æµ‹è¯•æ ·æœ¬: {sample['title']}")

    # 1. Humanizer å¤„ç†
    humanizer_result = run_humanizer(sample, llm_client)

    if humanizer_result['skipped']:
        print(f"  âš ï¸ Humanizer è·³è¿‡äº†æ”¹å†™ï¼ˆè¯„åˆ† {humanizer_result['score_before']} >= é˜ˆå€¼ï¼‰")
        print(f"  è¿™è¯´æ˜æ ·æœ¬ AI å‘³ä¸å¤Ÿé‡ï¼Œæˆ–é˜ˆå€¼è®¾ç½®è¿‡ä½")
        return None

    # æ£€æŸ¥å†…å®¹æ˜¯å¦å®é™…å‘ç”Ÿäº†å˜åŒ–
    if humanizer_result['original'].strip() == humanizer_result['humanized'].strip():
        print(f"  âš ï¸ Humanizer æœªæ”¹å˜å†…å®¹ï¼ˆå¯èƒ½ LLM è°ƒç”¨å¤±è´¥ï¼‰ï¼Œè·³è¿‡ Judge è¯„ä¼°")
        return None

    # 2. LLM Judge è¯„ä¼°
    eval_result = call_judge(
        humanizer_result['original'],
        humanizer_result['humanized'],
        llm_client,
    )

    # 3. è¾“å‡ºæŠ¥å‘Š
    print_eval_report(sample, humanizer_result, eval_result)

    # 4. ä¿å­˜ç»“æœ
    RESULTS_DIR.mkdir(parents=True, exist_ok=True)
    result_file = RESULTS_DIR / f"eval_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    eval_data = {
        "sample_title": sample['title'],
        "feature": "63-humanizer-agent",
        "humanizer_result": {
            "skipped": humanizer_result['skipped'],
            "score_before": humanizer_result['score_before'],
            "score_after": humanizer_result['score_after'],
            "elapsed": humanizer_result['elapsed'],
        },
        "eval_result": eval_result,
        "timestamp": datetime.now().isoformat(),
    }
    result_file.write_text(json.dumps(eval_data, ensure_ascii=False, indent=2))
    logger.info(f"  ğŸ’¾ è¯„ä¼°ç»“æœå·²ä¿å­˜: {result_file}")

    return eval_data


# ============================================================
# ä¸»å…¥å£
# ============================================================

def main():
    parser = argparse.ArgumentParser(description="[63] Humanizer Agent â€” LLM-as-Judge ç‰¹æ€§éªŒæ”¶")
    parser.add_argument("--backend-url", type=str, default=None, help="åç«¯ URL")
    args = parser.parse_args()

    if args.backend_url:
        global BACKEND_URL
        BACKEND_URL = args.backend_url

    print("=" * 70)
    print("ğŸ§ª ç‰¹æ€§éªŒæ”¶ï¼ˆ63 å·æ–¹æ¡ˆ â€” Humanizer Agent å» AI å‘³ï¼‰")
    print("=" * 70)

    llm_client = get_llm_client()

    all_pass = True
    for sample in AI_FLAVORED_SAMPLES:
        eval_data = run_eval(sample, llm_client)
        if eval_data is None:
            all_pass = False
        elif eval_data["eval_result"].get("verdict") != "PASS":
            all_pass = False

    print("\n" + "=" * 70)
    if all_pass:
        print("ğŸ‰ æ‰€æœ‰æ ·æœ¬éªŒæ”¶é€šè¿‡ï¼Humanizer Agent æœ‰æ•ˆæ¶ˆé™¤äº† AI å†™ä½œç—•è¿¹ã€‚")
    else:
        print("ğŸ’¥ éƒ¨åˆ†æ ·æœ¬éªŒæ”¶æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥ä¸Šæ–¹æŠ¥å‘Šä¸­çš„å¤±è´¥é¡¹ã€‚")
    print("=" * 70)


if __name__ == "__main__":
    sys.path.insert(0, str(Path(__file__).parent.parent))
    from dotenv import load_dotenv
    load_dotenv(Path(__file__).parent.parent / ".env")
    main()
